"""
Training script for Pong Autoencoder and DiT
è¨“ç·´ Pong çš„ Autoencoder å’Œ Diffusion Transformer
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm
import os
import matplotlib.pyplot as plt

from encoder import create_encoder
from decoder import create_decoder, create_dit, create_autoencoder


# ============================================================
# Dataset
# ============================================================

class PongFrameDataset(Dataset):
    """Pong éŠæˆ²ç•«é¢æ•¸æ“šé›†"""
    def __init__(self, frames, actions=None):
        """
        Args:
            frames: numpy array (N, H, W, C) æˆ– list of frames
            actions: numpy array (N,) å°æ‡‰çš„å‹•ä½œï¼ˆç”¨æ–¼ DiT è¨“ç·´ï¼‰
        """
        self.frames = frames
        self.actions = actions
        
    def __len__(self):
        return len(self.frames)
    
    def __getitem__(self, idx):
        frame = self.frames[idx]
        
        # è½‰æˆ tensor ä¸¦æ­£è¦åŒ–
        if isinstance(frame, np.ndarray):
            frame = torch.from_numpy(frame).float()
        
        # ç¢ºä¿æ˜¯ (C, H, W) æ ¼å¼
        if frame.shape[0] != 3:
            frame = frame.permute(2, 0, 1)
        
        # æ­£è¦åŒ–åˆ° [0, 1]
        if frame.max() > 1.0:
            frame = frame / 255.0
        
        if self.actions is not None:
            action = self.actions[idx]
            return frame, action
        
        return frame


# ============================================================
# Stage 1: è¨“ç·´ Autoencoder
# ============================================================

class AutoencoderTrainer:
    """Autoencoder è¨“ç·´å™¨"""
    def __init__(self, encoder, decoder, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.autoencoder = create_autoencoder(encoder, decoder).to(device)
        self.optimizer = optim.AdamW(self.autoencoder.parameters(), lr=1e-4, weight_decay=0.01)
        self.criterion = nn.MSELoss()
        
        self.train_losses = []
        self.val_losses = []
    
    def train_epoch(self, dataloader):
        """è¨“ç·´ä¸€å€‹ epoch"""
        self.autoencoder.train()
        total_loss = 0
        
        for frames in tqdm(dataloader, desc="Training"):
            frames = frames.to(self.device)
            
            # Forward pass
            reconstructed, latent = self.autoencoder(frames)
            loss = self.criterion(reconstructed, frames)
            
            # Backward pass
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / len(dataloader)
        self.train_losses.append(avg_loss)
        return avg_loss
    
    def validate(self, dataloader):
        """é©—è­‰"""
        self.autoencoder.eval()
        total_loss = 0
        
        with torch.no_grad():
            for frames in tqdm(dataloader, desc="Validating"):
                frames = frames.to(self.device)
                reconstructed, latent = self.autoencoder(frames)
                loss = self.criterion(reconstructed, frames)
                total_loss += loss.item()
        
        avg_loss = total_loss / len(dataloader)
        self.val_losses.append(avg_loss)
        return avg_loss
    
    def save(self, path):
        """å„²å­˜æ¨¡å‹"""
        torch.save({
            'encoder': self.autoencoder.encoder.state_dict(),
            'decoder': self.autoencoder.decoder.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'train_losses': self.train_losses,
            'val_losses': self.val_losses
        }, path)
        print(f"âœ… Model saved to {path}")
    
    def load(self, path):
        """è¼‰å…¥æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        self.autoencoder.encoder.load_state_dict(checkpoint['encoder'])
        self.autoencoder.decoder.load_state_dict(checkpoint['decoder'])
        self.optimizer.load_state_dict(checkpoint['optimizer'])
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        print(f"âœ… Model loaded from {path}")
    
    def plot_losses(self, save_path='training_curves.png'):
        """ç¹ªè£½è¨“ç·´æ›²ç·š"""
        plt.figure(figsize=(10, 5))
        plt.plot(self.train_losses, label='Train Loss')
        plt.plot(self.val_losses, label='Val Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Autoencoder Training Curves')
        plt.legend()
        plt.grid(True)
        plt.savefig(save_path)
        plt.close()
        print(f"âœ… Training curves saved to {save_path}")


# ============================================================
# Stage 2: è¨“ç·´ DiT
# ============================================================

class DiTTrainer:
    """DiT è¨“ç·´å™¨"""
    def __init__(self, dit, encoder, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.dit = dit.to(device)
        self.encoder = encoder.to(device)
        self.encoder.eval()  # Encoder å·²ç¶“è¨“ç·´å¥½ï¼Œè¨­ç‚ºè©•ä¼°æ¨¡å¼
        
        self.optimizer = optim.AdamW(self.dit.parameters(), lr=1e-4, weight_decay=0.01)
        self.criterion = nn.MSELoss()
        
        self.train_losses = []
    
    def add_noise(self, latent, timesteps):
        """æ·»åŠ å™ªè²ï¼ˆç°¡åŒ–ç‰ˆ diffusionï¼‰"""
        noise = torch.randn_like(latent)
        # ç°¡å–®çš„ç·šæ€§å™ªè²èª¿åº¦
        alpha = 1.0 - timesteps.float().unsqueeze(-1).unsqueeze(-1) / 1000.0
        noisy_latent = alpha * latent + (1 - alpha) * noise
        return noisy_latent, noise
    
    def train_epoch(self, dataloader):
        """è¨“ç·´ä¸€å€‹ epoch"""
        self.dit.train()
        total_loss = 0
        
        for frames, actions in tqdm(dataloader, desc="Training DiT"):
            frames = frames.to(self.device)
            actions = actions.to(self.device)
            
            # 1. ç”¨ encoder ç·¨ç¢¼ç•«é¢
            with torch.no_grad():
                latent = self.encoder(frames)
            
            # 2. æ·»åŠ å™ªè²
            batch_size = frames.shape[0]
            timesteps = torch.randint(0, 1000, (batch_size,), device=self.device)
            noisy_latent, noise = self.add_noise(latent, timesteps)
            
            # 3. DiT é æ¸¬å™ªè²
            pred_noise = self.dit(noisy_latent, timesteps, actions)
            
            # 4. è¨ˆç®—æå¤±
            loss = self.criterion(pred_noise, noise)
            
            # 5. æ›´æ–°
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / len(dataloader)
        self.train_losses.append(avg_loss)
        return avg_loss
    
    def save(self, path):
        """å„²å­˜æ¨¡å‹"""
        torch.save({
            'dit': self.dit.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'train_losses': self.train_losses
        }, path)
        print(f"âœ… DiT is saved to {path}")
    
    def load(self, path):
        """è¼‰å…¥æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        self.dit.load_state_dict(checkpoint['dit'])
        self.optimizer.load_state_dict(checkpoint['optimizer'])
        self.train_losses = checkpoint.get('train_losses', [])
        print(f"âœ… DiT is loaded from {path}")


# ============================================================
# ä¸»è¦è¨“ç·´å‡½æ•¸
# ============================================================

def collect_pong_data(num_frames=1000, view=False):
    """æ”¶é›† Pong éŠæˆ²æ•¸æ“š"""
    print(f"ğŸ“Š Collecting {num_frames} frames of Pong data...")
    
    from pong import Pong
    import gymnasium
    import ale_py
    
    gymnasium.register_envs(ale_py)
    render_mode = "human" if view else "rgb_array"
    env = gymnasium.make("ALE/Pong-v5", render_mode=render_mode, frameskip=1)
    
    frames = []
    actions = []
    
    obs, info = env.reset()
    
    for i in tqdm(range(num_frames), desc="Collecting frames"):
        # ç²å–ç•«é¢
        frame = env.unwrapped.get_wrapper_attr("ale").getScreenRGB()
        frames.append(frame)
        
        # éš¨æ©Ÿå‹•ä½œ
        action = env.action_space.sample()
        actions.append(action)
        
        obs, reward, terminated, truncated, info = env.step(action)
        
        if terminated or truncated:
            obs, info = env.reset()
    
    env.close()
    
    frames = np.array(frames)
    actions = np.array(actions)
    
    print(f"âœ… Data collection complete.")
    print(f"   - Frames shape: {frames.shape}")
    print(f"   - Actions shape: {actions.shape}")
    
    return frames, actions


def train_autoencoder(frames, epochs=50, batch_size=32, save_dir='checkpoints'):
    """è¨“ç·´ Autoencoder"""
    print("\n" + "=" * 70)
    print("ğŸš€ Start training Autoencoder")
    print("=" * 70)
    
    # å‰µå»ºç›®éŒ„
    os.makedirs(save_dir, exist_ok=True)
    
    # åˆ†å‰²è¨“ç·´/é©—è­‰é›†
    split_idx = int(len(frames) * 0.9)
    train_frames = frames[:split_idx]
    val_frames = frames[split_idx:]
    
    # å‰µå»ºæ•¸æ“šé›†
    train_dataset = PongFrameDataset(train_frames)
    val_dataset = PongFrameDataset(val_frames)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    # å‰µå»ºæ¨¡å‹
    encoder = create_encoder()
    decoder = create_decoder()
    trainer = AutoencoderTrainer(encoder, decoder)
    
    print(f"\nModel parameters: {sum(p.numel() for p in trainer.autoencoder.parameters()):,}")
    print(f"Number of training samples: {len(train_dataset)}")
    print(f"Number of validation samples: {len(val_dataset)}")
    
    # è¨“ç·´
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        print(f"\nğŸ“ Epoch {epoch+1}/{epochs}")
        
        train_loss = trainer.train_epoch(train_loader)
        val_loss = trainer.validate(val_loader)
        
        print(f"   Train Loss: {train_loss:.6f}")
        print(f"   Val Loss: {val_loss:.6f}")
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            trainer.save(os.path.join(save_dir, 'best_autoencoder.pth'))
            print(f"   ğŸŒŸ New best model!")
        
        # å®šæœŸå„²å­˜
        if (epoch + 1) % 10 == 0:
            trainer.save(os.path.join(save_dir, f'autoencoder_epoch_{epoch+1}.pth'))
    
    # ç¹ªè£½è¨“ç·´æ›²ç·š
    trainer.plot_losses(os.path.join(save_dir, 'autoencoder_curves.png'))
    
    return trainer


def train_dit(frames, actions, encoder, epochs=30, batch_size=32, save_dir='checkpoints'):
    """è¨“ç·´ DiT"""
    print("\n" + "=" * 70)
    print("ğŸŒŸ Start training DiT")
    print("=" * 70)
    
    # å‰µå»ºæ•¸æ“šé›†ï¼ˆéœ€è¦é…å°çš„ frame å’Œ actionï¼‰
    dataset = PongFrameDataset(frames, actions)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # å‰µå»ºæ¨¡å‹
    dit = create_dit()
    trainer = DiTTrainer(dit, encoder)
    
    print(f"\nDiT parameters: {sum(p.numel() for p in dit.parameters()):,}")
    print(f"Number of training samples: {len(dataset)}")
    
    # è¨“ç·´
    for epoch in range(epochs):
        print(f"\nğŸ“ Epoch {epoch+1}/{epochs}")
        
        train_loss = trainer.train_epoch(dataloader)
        print(f"   Train Loss: {train_loss:.6f}")
        
        # å®šæœŸå„²å­˜
        if (epoch + 1) % 5 == 0:
            trainer.save(os.path.join(save_dir, f'dit_epoch_{epoch+1}.pth'))
    
    # å„²å­˜æœ€çµ‚æ¨¡å‹
    trainer.save(os.path.join(save_dir, 'dit_final.pth'))
    
    return trainer


# ============================================================
# ä¸»ç¨‹å¼
# ============================================================

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ® Pong AI Training Pipeline")
    print("=" * 70)
    
    # è¨­å®š
    NUM_FRAMES = 5000  # æ”¶é›†çš„ç•«é¢æ•¸é‡
    AUTOENCODER_EPOCHS = 20  # Autoencoder è¨“ç·´è¼ªæ•¸
    DIT_EPOCHS = 15  # DiT è¨“ç·´è¼ªæ•¸
    BATCH_SIZE = 16
    
    # Step 1: æ”¶é›†æ•¸æ“š
    print("\nğŸ“Š Step 1: Collecting Game Data")
    frames, actions = collect_pong_data(num_frames=NUM_FRAMES, view=False)
    
    # Step 2: è¨“ç·´ Autoencoder
    print("\nğŸ”§ Step 2: Training Autoencoder")
    ae_trainer = train_autoencoder(
        frames, 
        epochs=AUTOENCODER_EPOCHS, 
        batch_size=BATCH_SIZE
    )
    
    # Step 3: è¨“ç·´ DiT
    print("\nâœ¨ Step 3: Training DiT")
    dit_trainer = train_dit(
        frames, 
        actions, 
        ae_trainer.autoencoder.encoder,
        epochs=DIT_EPOCHS,
        batch_size=BATCH_SIZE
    )
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Training complete!")
    print("=" * 70)
    print("\nModel saved to the checkpoints/ directory")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. Check checkpoints/autoencoder_curves.png to review training performance")
    print("2. Use the trained model to generate new Pong frames")
    print("3. Try using DiT to generate a playable game!")
